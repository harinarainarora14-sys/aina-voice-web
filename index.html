<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Aina ‚Ä¢ Mood + Voice Assistant</title>
  <style>
    :root {
      --bg:#0b1020; --card:#121a33; --ink:#e7ebf3; --muted:#cfd8f3;
      --btn:#0c1329; --btn-br:rgba(255,255,255,.12);
      --glow1:#7c9cff; --glow2:#b9e0ff;
    }
    * { box-sizing:border-box; }
    body {
      margin:0; background:var(--bg); color:var(--ink);
      font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
      min-height:100vh; display:flex; align-items:center; justify-content:center;
      padding:24px;
    }
    .wrap {
      width:100%; max-width:1100px; display:grid; gap:24px;
      grid-template-columns: repeat(2, minmax(280px, 1fr));
    }
    @media (max-width: 860px){ .wrap{ grid-template-columns: 1fr; } }

    .card {
      background:var(--card); border-radius:16px; padding:20px;
      box-shadow:0 10px 30px rgba(0,0,0,.35);
    }
    h1 { margin:0 0 10px; font-size:22px; }
    .sub { opacity:.8; font-size:14px; margin-bottom:14px; }

    button {
      background:var(--btn); color:var(--ink);
      border:1px solid var(--btn-br);
      padding:10px 14px; border-radius:12px; cursor:pointer;
      font-size:14px; transition:transform .15s ease, border-color .15s ease;
    }
    button:hover { transform:scale(1.05); border-color:var(--glow1); }
    button[disabled]{ opacity:.6; cursor:not-allowed; transform:none; }

    input[type="text"]{
      width:100%; padding:12px; border-radius:12px; border:1px solid var(--btn-br);
      background:var(--btn); color:var(--ink); outline:none;
    }

    .row{ display:flex; gap:8px; flex-wrap:wrap; align-items:center; }
    .result { margin-top:14px; font-size:16px; line-height:1.6; }
    .glow-text {
      font-weight:600; font-size:18px;
      background: linear-gradient(90deg, var(--glow1), var(--glow2), var(--glow1));
      -webkit-background-clip:text; background-clip:text; -webkit-text-fill-color:transparent;
      animation: glow 3s infinite alternate;
    }
    @keyframes glow {
      from { text-shadow:0 0 10px var(--glow1), 0 0 20px var(--glow1); }
      to   { text-shadow:0 0 20px var(--glow2), 0 0 30px var(--glow1); }
    }
    .exercise { margin-top:8px; font-size:15px; color:var(--muted); text-shadow:0 0 8px rgba(124,156,255,.5); }

    /* Voice Assistant sections */
    .modebar { display:flex; gap:8px; margin:8px 0 12px; }
    .modebar button.active { border-color:var(--glow1); transform:scale(1.03); }
    .panel { display:none; }
    .panel.show{ display:block; }
    .answer { min-height:48px; }

    /* tiny helper text */
    .hint { font-size:12px; opacity:.75; margin-top:6px; }
  </style>
</head>
<body>
  <div class="wrap">
    <!-- Mood Detector (Aina look, unchanged logic) -->
    <div class="card">
      <h1>Mood Detector</h1>
      <div class="sub">Analyze your facial expression for 4 seconds.</div>
      <div class="row">
        <button id="startMood">Start</button>
      </div>
      <div id="moodResult" class="result">Press Start to analyze your mood.</div>
      <video id="video" autoplay muted playsinline style="display:none"></video>
      <canvas id="overlay" style="display:none"></canvas>
    </div>

    <!-- Voice Assistant (Aina-styled, 3 modes, auto TTS, Start/Stop) -->
    <div class="card">
      <h1>Voice Assistant</h1>
      <div class="sub">Ask by typing, single voice shot, or continuous conversation.</div>

      <!-- Mode Switch -->
      <div class="modebar">
        <button id="mText"   class="active">Text Mode</button>
        <button id="mVoice">Voice Chat</button>
        <button id="mCont">Voice Continuous</button>
        <div style="flex:1"></div>
        <button id="stopAll">‚èπ Stop</button>
      </div>

      <!-- Text Mode -->
      <div id="panelText" class="panel show">
        <div class="row" style="margin-bottom:8px">
          <input id="textIn" placeholder="Type your message‚Ä¶"
                 onkeydown="if(event.key==='Enter'){event.preventDefault(); sendText();}">
          <button id="sendBtn">Send</button>
        </div>
        <div class="hint">Auto-speaks every reply. ‚ÄúStop‚Äù cancels speech.</div>
      </div>

      <!-- Voice Mode -->
      <div id="panelVoice" class="panel">
        <div class="row">
          <button id="startVoice">üé§ Start Listening</button>
          <button id="stopVoice">‚èπ Stop</button>
        </div>
        <div class="hint">Single utterance ‚Üí answer ‚Üí auto-speak.</div>
      </div>

      <!-- Continuous Voice Mode -->
      <div id="panelCont" class="panel">
        <div class="row">
          <button id="startCont">üîÑ Start Continuous</button>
          <button id="stopCont">‚èπ Stop</button>
        </div>
        <div class="hint">Keeps listening and responding until you press Stop.</div>
      </div>

      <!-- Answer -->
      <div id="answer" class="result answer">Ask something by text or voice.</div>
    </div>
  </div>

  <!-- Face API for Mood Detector -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
  <script>
    /*************** CONFIG ***************/
    const API_URL = "https://voice-assistant-api-yya9.onrender.com/ask"; // your deployed FastAPI

    /*************** UTIL: TTS (auto-speak, cancel previous) ***************/
    let audioUnlocked = false;
    let currentUtterance = null;

    // iOS/Android: unlock audio on first user gesture
    window.addEventListener('click', () => {
      if (!audioUnlocked) {
        try {
          const u = new SpeechSynthesisUtterance(" ");
          u.volume = 0; // silent unlock
          speechSynthesis.speak(u);
        } catch(e){}
        audioUnlocked = true;
      }
    }, { once:true });

    function speak(text) {
      if (!text) return;
      try {
        if (speechSynthesis.speaking) speechSynthesis.cancel();
        currentUtterance = new SpeechSynthesisUtterance(text);
        // You can adjust these if you want:
        // currentUtterance.rate = 1; currentUtterance.pitch = 1; currentUtterance.volume = 1;
        speechSynthesis.speak(currentUtterance);
      } catch (e) {
        console.warn("TTS error:", e);
      }
    }
    function stopSpeaking() {
      try { speechSynthesis.cancel(); } catch(e){}
    }

    /*************** VOICE ASSISTANT: Modes + API ***************/
    const mText = document.getElementById('mText');
    const mVoice = document.getElementById('mVoice');
    const mCont  = document.getElementById('mCont');
    const panelText = document.getElementById('panelText');
    const panelVoice = document.getElementById('panelVoice');
    const panelCont  = document.getElementById('panelCont');
    const stopAllBtn = document.getElementById('stopAll');
    const answerEl = document.getElementById('answer');

    function setMode(which){
      [mText,mVoice,mCont].forEach(b=>b.classList.remove('active'));
      [panelText,panelVoice,panelCont].forEach(p=>p.classList.remove('show'));
      if (which==='text'){ mText.classList.add('active'); panelText.classList.add('show'); stopVoiceRec(); }
      if (which==='voice'){ mVoice.classList.add('active'); panelVoice.classList.add('show'); stopVoiceRec(); }
      if (which==='cont'){ mCont.classList.add('active'); panelCont.classList.add('show'); startContinuous(); }
    }
    mText.onclick = ()=> setMode('text');
    mVoice.onclick= ()=> setMode('voice');
    mCont.onclick = ()=> setMode('cont');

    // API call helper
    async function ask(question){
      stopSpeaking(); // cancel any ongoing speech before new request
      answerEl.textContent = "Thinking‚Ä¶";
      try{
        const res = await fetch(`${API_URL}?question=${encodeURIComponent(question)}`);
        const data = await res.json();
        const txt = (data && data.answer) ? data.answer : "No answer received.";
        answerEl.innerHTML = `<span class="glow-text">${txt}</span>`;
        speak(txt); // auto-speak every reply
      } catch(e){
        console.error(e);
        answerEl.textContent = "Error connecting to API.";
      }
    }

    // Text mode
    const textIn = document.getElementById('textIn');
    document.getElementById('sendBtn').onclick = ()=>{
      const q = textIn.value.trim();
      if (!q) return;
      ask(q);
      textIn.value = "";
    };

    // Voice modes (webkitSpeechRecognition)
    let rec = null;
    let contModeActive = false;

    function newRecognizer(isContinuous){
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR){ alert("Speech recognition is not supported in this browser."); return null; }
      const r = new SR();
      r.lang = "en-US";
      r.continuous = isContinuous;
      r.interimResults = false;

      r.onresult = (e)=>{
        // Handle possibly multiple results (esp. in continuous)
        for (let i=e.resultIndex; i<e.results.length; i++){
          if (e.results[i].isFinal){
            const transcript = e.results[i][0].transcript;
            ask(transcript);
          }
        }
      };
      r.onerror = (e)=> console.warn("SR error:", e);
      r.onend = ()=>{
        if (contModeActive) {
          // restart seamlessly in continuous mode
          try { r.start(); } catch(e){}
        }
      };
      return r;
    }

    // Single-shot voice
    const startVoice = document.getElementById('startVoice');
    const stopVoice  = document.getElementById('stopVoice');
    startVoice.onclick = ()=>{
      stopVoiceRec();
      rec = newRecognizer(false);
      if (rec) rec.start();
    };
    stopVoice.onclick = ()=> stopVoiceRec();

    // Continuous
    const startCont = document.getElementById('startCont');
    const stopCont  = document.getElementById('stopCont');
    function startContinuous(){
      stopVoiceRec();
      contModeActive = true;
      rec = newRecognizer(true);
      if (rec) rec.start();
    }
    function stopVoiceRec(){
      contModeActive = false;
      try { if (rec) rec.onend = null; } catch(e){}
      try { if (rec) rec.stop(); } catch(e){}
      rec = null;
    }
    startCont.onclick = ()=> startContinuous();
    stopCont.onclick  = ()=> stopVoiceRec();

    // Global stop button: stops recognition + speech
    stopAllBtn.onclick = ()=>{
      stopVoiceRec();
      stopSpeaking();
      answerEl.textContent = "Stopped.";
    };

    /*************** MOOD DETECTOR (unchanged logic, Aina style) ***************/
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const moodResult = document.getElementById('moodResult');
    const startMoodBtn = document.getElementById('startMood');
    let stream = null;
    const MODEL_URL = 'https://cdn.jsdelivr.net/gh/vladmandic/face-api/model/';

    async function loadModels() {
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),
      ]);
    }
    async function startCamera() {
      if (!stream) {
        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
        video.srcObject = stream;
        await video.play();
      }
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }
    function topExpression(expressions) {
      let best = { key: 'neutral', val: 0 };
      for (const [k, v] of Object.entries(expressions)) if (v > best.val) best = { key:k, val:v };
      return best;
    }
    function moodMessage(emotion) {
      const map = {
        angry:{quote:"I am in control of my emotions, not the other way around.",exercise:"Box Breathing: Inhale 4, hold 4, exhale 4, hold 4."},
        happy:{quote:"Happiness flows through me like a gentle river, endless and free.",exercise:"Think 3 things you're grateful for."},
        sad:{quote:"This feeling is temporary, brighter days are on their way.",exercise:"5-4-3-2-1 Grounding."},
        neutral:{quote:"Your calm presence is a quiet kind of beauty.",exercise:"Stretch your body lightly."},
        surprised:{quote:"Every unexpected moment carries a hidden gift.",exercise:"Notice 3 familiar things."},
        fearful:{quote:"Your fear is a passing cloud; your strength is the sky.",exercise:"Take 5 slow breaths."},
        disgusted:{quote:"What disturbs you doesn't have to stay within you.",exercise:"Listen to a calming song."},
      };
      return map[emotion] || {quote:"Stay mindful.", exercise:"Take a short pause."};
    }
    async function analyzeMood() {
      await startCamera();
      moodResult.textContent = "Analyzing for 4 seconds‚Ä¶";
      startMoodBtn.disabled = true;

      const collected = [];
      const start = Date.now();

      async function capture(){
        const opts = new faceapi.TinyFaceDetectorOptions({ inputSize:512, scoreThreshold:0.5 });
        const det = await faceapi.detectSingleFace(video, opts).withFaceExpressions();
        if (det) collected.push(det.expressions);

        if (Date.now() - start < 4000) requestAnimationFrame(capture);
        else {
          if (!collected.length) {
            moodResult.textContent = "No face detected.";
            startMoodBtn.disabled = false; return;
          }
          const avg = {};
          collected.forEach(exp=>{
            for (const [k,v] of Object.entries(exp)) avg[k] = (avg[k]||0)+v;
          });
          for (const k in avg) avg[k] /= collected.length;

          const { key, val } = topExpression(avg);
          const msg = moodMessage(key);
          moodResult.innerHTML =
            `<strong>Mood:</strong> ${key} (${(val*100).toFixed(1)}%)<br>
             <span class="glow-text">${msg.quote}</span>
             <div class="exercise">${msg.exercise}</div>`;
          startMoodBtn.disabled = false;
        }
      }
      capture();
    }
    startMoodBtn.addEventListener('click', analyzeMood);
    loadModels();
  </script>
</body>
</html>
