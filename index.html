<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Aina ‚Ä¢ Mood + Voice Assistant</title>
  <style>
    :root {
      --bg:#0b1020; --card:#121a33; --ink:#e7ebf3; --muted:#cfd8f3;
      --btn:#0c1329; --btn-br:rgba(255,255,255,.12);
      --glow1:#7c9cff; --glow2:#b9e0ff;
    }
    * { box-sizing:border-box; }
    html,body { height:100%; }
    body {
      margin:0; background:var(--bg); color:var(--ink);
      font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
      min-height:100vh; display:flex; flex-direction:column;
      align-items:center; justify-content:center;
      padding:24px; gap:24px;
    }
    .wrap { width:100%; max-width:1100px; display:flex; gap:24px;
      flex-wrap:wrap; justify-content:center; align-items:flex-start; }
    .wrap.solo { justify-content:center; }
    .wrap.solo .card#moodCard { max-width:640px; width:100%; }

    .card {
      background:var(--card); border-radius:16px; padding:20px;
      box-shadow:0 10px 30px rgba(0,0,0,.35);
      flex:1; min-width:300px; max-width:500px;
    }
    h1 { margin:0 0 10px; font-size:22px; }
    .sub { opacity:.8; font-size:14px; margin-bottom:14px; }

    button {
      background:var(--btn); color:var(--ink);
      border:1px solid var(--btn-br);
      padding:10px 14px; border-radius:12px; cursor:pointer;
      font-size:14px; transition:transform .15s ease, border-color .15s ease;
    }
    button:hover { transform:scale(1.05); border-color:var(--glow1); }
    button[disabled]{ opacity:.6; cursor:not-allowed; transform:none; }

    input[type="text"]{
      width:100%; padding:12px; border-radius:12px; border:1px solid var(--btn-br);
      background:var(--btn); color:var(--ink); outline:none;
    }
    .row{ display:flex; gap:8px; flex-wrap:wrap; align-items:center; }
    .result { margin-top:14px; font-size:16px; line-height:1.6; }
    .glow-text {
      font-weight:600; font-size:18px;
      background: linear-gradient(90deg, var(--glow1), var(--glow2), var(--glow1));
      -webkit-background-clip:text; background-clip:text; -webkit-text-fill-color:transparent;
      animation: glow 3s infinite alternate;
    }
    @keyframes glow {
      from { text-shadow:0 0 10px var(--glow1), 0 0 20px var(--glow1); }
      to   { text-shadow:0 0 20px var(--glow2), 0 0 30px var(--glow1); }
    }
    .exercise { margin-top:8px; font-size:15px; color:var(--muted); text-shadow:0 0 8px rgba(124,156,255,.5); }

    .modebar { display:flex; gap:8px; margin:8px 0 12px; align-items:center; }
    .modebar button.active { border-color:var(--glow1); transform:scale(1.03); }
    .panel { display:none; }
    .panel.show{ display:block; }
    .answer { min-height:48px; }
    .hint { font-size:12px; opacity:.75; margin-top:6px; }

    #toggleVoice {
      position:fixed; bottom:20px; right:20px; z-index:1000;
      background:var(--card); border:1px solid var(--btn-br);
      border-radius:20px; padding:10px 16px;
      box-shadow:0 4px 12px rgba(0,0,0,.4);
    }
    #toggleVoice.pulse { animation: pulse 1.6s infinite; border-color:var(--glow1); }
    @keyframes pulse {
      0% { box-shadow:0 0 0 0 rgba(124,156,255,0.12); }
      70% { box-shadow:0 0 0 8px rgba(124,156,255,0.02); }
      100% { box-shadow:0 0 0 0 rgba(124,156,255,0.0); }
    }
  </style>
</head>
<body>
  <div class="wrap" id="mainWrap">
    <!-- Mood Detector -->
    <div class="card" id="moodCard">
      <h1>Mood Detector</h1>
      <div class="sub">Analyze your facial expression for 4 seconds.</div>
      <div class="row">
        <button id="startMood">Start</button>
      </div>
      <div id="moodResult" class="result">Press Start to analyze your mood.</div>
      <video id="video" autoplay muted playsinline style="display:none"></video>
      <canvas id="overlay" style="display:none"></canvas>
    </div>

    <!-- Voice Assistant -->
    <div class="card" id="voiceCard">
      <h1>Voice Assistant</h1>
      <div class="sub">Ask by typing, single voice shot, or continuous conversation.</div>

      <div class="modebar">
        <button id="mText" class="active">Text Mode</button>
        <button id="mVoice">Voice Chat</button>
        <button id="mCont">Voice Continuous</button>
        <div style="flex:1"></div>
        <button id="stopAll">‚èπ Stop</button>
      </div>

      <div id="panelText" class="panel show">
        <div class="row" style="margin-bottom:8px; width:100%">
          <input id="textIn" type="text" placeholder="Type your message‚Ä¶" />
          <button id="sendBtn">Send</button>
        </div>
        <div class="hint">Auto-speaks every reply. ‚ÄúStop‚Äù cancels speech.</div>
      </div>

      <div id="panelVoice" class="panel">
        <div class="row">
          <button id="startVoice">üé§ Start Listening</button>
        </div>
        <div class="hint">Single utterance ‚Üí answer ‚Üí auto-speak.</div>
      </div>

      <div id="panelCont" class="panel">
        <div class="row">
          <button id="startCont">üîÑ Start Continuous</button>
        </div>
        <div class="hint">Keeps listening and responding until you press Stop.</div>
      </div>

      <div id="answer" class="result answer">Ask something by text or voice.</div>
    </div>
  </div>

  <button id="toggleVoice">Hide Assistant</button>

  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
  <script>
    /*************** CONFIG ***************/
    const API_URL = "https://voice-assistant-api-yya9.onrender.com/ask";

    /*************** TTS ***************/
    let audioUnlocked = false;
    let currentUtterance = null;
    ["click","touchstart","pointerdown"].forEach(evt=>{
      window.addEventListener(evt, () => {
        if (!audioUnlocked) {
          try {
            const u = new SpeechSynthesisUtterance(" ");
            u.volume = 0;
            speechSynthesis.speak(u);
          } catch(e){}
          audioUnlocked = true;
        }
      }, { once:true });
    });
    function speak(text) {
      if (!text) return;
      try {
        speechSynthesis.cancel();
        currentUtterance = new SpeechSynthesisUtterance(text);
        speechSynthesis.speak(currentUtterance);
      } catch (e) {}
    }
    function stopSpeaking() { try { speechSynthesis.cancel(); } catch(e){} }

    /*************** Elements ***************/
    const startMoodBtn = document.getElementById('startMood');
    const startVoice = document.getElementById('startVoice');
    const stopAllBtn = document.getElementById('stopAll');

    /*************** Recognition ***************/
    let rec = null;
    let contModeActive = false;
    function newRecognizer(isContinuous){
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR){ alert("Speech recognition not supported."); return null; }
      const r = new SR();
      r.lang = "en-US";
      r.continuous = isContinuous;
      r.interimResults = false;
      r.onresult = (e)=>{
        for (let i=e.resultIndex; i<e.results.length; i++){
          if (e.results[i].isFinal){
            const transcript = e.results[i][0].transcript.trim();
            if (transcript) ask(transcript);
          }
        }
      };
      r.onend = ()=>{ if (isContinuous && contModeActive) setTimeout(()=>{ try{r.start();}catch(e){} },250); };
      return r;
    }
    function stopVoiceRec(){
      contModeActive = false;
      try { if (rec) rec.onend = null; } catch(e){}
      try { if (rec) rec.stop(); } catch(e){}
      rec = null;
    }

    // Start voice (one-shot)
    startVoice.onclick = ()=>{
      stopVoiceRec();
      rec = newRecognizer(false);
      if (rec) { try { rec.start(); } catch(e){} }
    };

    // Stop all
    stopAllBtn.onclick = ()=>{
      stopVoiceRec();
      stopSpeaking();
    };

    /*************** Mood Detector ***************/
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const moodResult = document.getElementById('moodResult');
    let stream = null;
    const MODEL_URL = 'https://cdn.jsdelivr.net/gh/vladmandic/face-api/model/';
    async function loadModels() {
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),
      ]);
    }
    async function startCamera() {
      if (!stream) {
        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
        video.srcObject = stream;
        await video.play();
      }
      canvas.width = video.videoWidth || 640;
      canvas.height = video.videoHeight || 480;
    }
    function topExpression(expressions) {
      let best = { key: 'neutral', val: 0 };
      for (const [k, v] of Object.entries(expressions)) if (v > best.val) best = { key:k, val:v };
      return best;
    }
    function moodMessage(emotion) {
      const map = { happy:{quote:"Happiness flows.",exercise:"Think 3 things you're grateful for."}, sad:{quote:"This feeling is temporary.",exercise:"5-4-3-2-1 Grounding."}, neutral:{quote:"Your calm presence is beauty.",exercise:"Stretch lightly."}, angry:{quote:"You control your emotions.",exercise:"Box breathing."}, surprised:{quote:"Unexpected brings gifts.",exercise:"Notice 3 familiar things."}, fearful:{quote:"Fear passes.",exercise:"Take 5 breaths."}, disgusted:{quote:"Let it go.",exercise:"Listen to music."}};
      return map[emotion] || {quote:"Stay mindful.", exercise:"Take a pause."};
    }
    async function analyzeMood() {
      try { await startCamera(); } catch(e){ moodResult.textContent="Camera needed."; startMoodBtn.disabled=false; return; }
      moodResult.textContent = "Analyzing for 4 seconds‚Ä¶";
      startMoodBtn.disabled = true;
      const collected = [];
      const start = Date.now();
      async function capture(){
        const opts = new faceapi.TinyFaceDetectorOptions({ inputSize:512, scoreThreshold:0.5 });
        const det = await faceapi.detectSingleFace(video, opts).withFaceExpressions();
        if (det) collected.push(det.expressions);
        if (Date.now() - start < 4000) requestAnimationFrame(capture);
        else {
          if (!collected.length){ moodResult.textContent="No face detected."; startMoodBtn.disabled=false; return; }
          const avg = {};
          collected.forEach(exp=>{ for (const [k,v] of Object.entries(exp)) avg[k]=(avg[k]||0)+v; });
          for (const k in avg) avg[k] /= collected.length;
          const { key, val } = topExpression(avg);
          const msg = moodMessage(key);
          moodResult.innerHTML = `<strong>Mood:</strong> ${key} (${(val*100).toFixed(1)}%)<br><span class="glow-text">${msg.quote}</span><div class="exercise">${msg.exercise}</div>`;
          startMoodBtn.disabled = false;
        }
      }
      capture();
    }
    startMoodBtn.addEventListener('click', analyzeMood);
    loadModels();

    /*************** API ***************/
    const answerEl = document.getElementById('answer');
    async function ask(question){
      if (!question) return;
      stopSpeaking();
      answerEl.textContent = "Thinking‚Ä¶";
      try{
        const res = await fetch(`${API_URL}?question=${encodeURIComponent(question)}`);
        const data = await res.json();
        const txt = (data && data.answer) ? data.answer : "No answer.";
        answerEl.innerHTML = `<span class="glow-text">${txt}</span>`;
        speak(txt);
      }catch(e){ answerEl.textContent="API error."; }
    }

    /*************** Hotkeys ***************/
    document.addEventListener("keydown", (e)=>{
      if (e.code === "F1") { e.preventDefault(); startMoodBtn.click(); }
      if (e.code === "F2") { e.preventDefault(); startVoice.click(); }
      if (e.code === "F3") { e.preventDefault(); stopAllBtn.click(); }
    });
  </script>
</body>
</html>

